{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TL;DR"
      ],
      "metadata": {
        "id": "VL0f2SGp2T4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuring Enviorment**"
      ],
      "metadata": {
        "id": "FwEh3AdS2eny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "installing dependencies"
      ],
      "metadata": {
        "id": "B8wNu87731OU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYCQ9zV71rDr",
        "outputId": "8734c51d-e2e7-451c-b537-bae8383877ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk spacy beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import spacy\n",
        "from time import time\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, SimpleRNN\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "f6u-yy5A30DY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Set Google Drive**\n"
      ],
      "metadata": {
        "id": "A0hwVeTbmDns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM2UoL0Al9ye",
        "outputId": "b0f3f133-ab96-4808-f742-4fce1e06e3ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_DRIVE_PATH = '/content/drive/MyDrive'\n",
        "print(os.listdir('/content/drive/MyDrive'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JrD4yJdq7aY",
        "outputId": "ac04a243-898b-4bcf-b04e-4b013cce01d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Photos', 'Books', 'Android games', 'תמונה (55).jpg', 'nativ', 'קנבס לגף אוהד.png', 'samples.csv', 'Selected issues in enginnering ethics', 'Colab Notebooks', 'Copy of Warframe Mastery Checklist V2.gsheet', 'Controls and compliance checklist.gdoc', 'Botium Toys: Scope, goals, and risk assessment report.gdoc', 'Cybersecurity incident report network traffic analysis.gdoc', 'Example of a Cybersecurity Incident Report.gdoc', 'spam.csv', 'homework1-2324.pdf', 'WhatsApp Chat with Friends.txt', 'data.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Load data***\n",
        "\n",
        "this data is not from homework 1 and 2 cause i found a better way to extract data from reddit."
      ],
      "metadata": {
        "id": "t4G7LnhAw6p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/data.csv', sep='\\t')\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "mI18dOIgy_Xd",
        "outputId": "b311193f-70f0-4610-fa96-973758c03cf4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              title  \\\n",
              "0           0  I'm f'ed up and I cannot fix it no matter what...   \n",
              "1           1  I'm 45 years of age and still suck my thumb as...   \n",
              "2           2  I only paid for half of the price of a cake, k...   \n",
              "3           3  I lied on my resume because I was desperate fo...   \n",
              "4           4  [Extreme Remorse] I relieved my pets from suff...   \n",
              "\n",
              "                                            selftext       id  \\\n",
              "0  When I was younger I was fat, but I'm hilariou...  1e4xvti   \n",
              "1  I'm 45 M and still suck my thumb and honestly ...  1e4xvcj   \n",
              "2  More than a year ago, I went to my local groce...  1e4iomq   \n",
              "3  I recently graduated from grad school and have...  1e4fg9e   \n",
              "4  [Extreme Remorse]\\n\\nI grew up with pets. Yeah...  1e4cg3w   \n",
              "\n",
              "                                         clean_title  \\\n",
              "0  im fed up and i cannot fix it no matter what i do   \n",
              "1  im  years of age and still suck my thumb as a ...   \n",
              "2  i only paid for half of the price of a cake kn...   \n",
              "3  i lied on my resume because i was desperate fo...   \n",
              "4  extreme remorse i relieved my pets from suffering   \n",
              "\n",
              "                                      clean_selftext clean_id  \n",
              "0  when i was younger i was fat but im hilarious ...    exvti  \n",
              "1  im  m and still suck my thumb and honestly don...    exvcj  \n",
              "2  more than a year ago i went to my local grocer...    eiomq  \n",
              "3  i recently graduated from grad school and have...     efge  \n",
              "4  extreme remorse\\n\\ni grew up with pets yeah yo...     ecgw  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a325257-3a23-4f1a-a5c4-0bf1967d319c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>selftext</th>\n",
              "      <th>id</th>\n",
              "      <th>clean_title</th>\n",
              "      <th>clean_selftext</th>\n",
              "      <th>clean_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>I'm f'ed up and I cannot fix it no matter what...</td>\n",
              "      <td>When I was younger I was fat, but I'm hilariou...</td>\n",
              "      <td>1e4xvti</td>\n",
              "      <td>im fed up and i cannot fix it no matter what i do</td>\n",
              "      <td>when i was younger i was fat but im hilarious ...</td>\n",
              "      <td>exvti</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I'm 45 years of age and still suck my thumb as...</td>\n",
              "      <td>I'm 45 M and still suck my thumb and honestly ...</td>\n",
              "      <td>1e4xvcj</td>\n",
              "      <td>im  years of age and still suck my thumb as a ...</td>\n",
              "      <td>im  m and still suck my thumb and honestly don...</td>\n",
              "      <td>exvcj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I only paid for half of the price of a cake, k...</td>\n",
              "      <td>More than a year ago, I went to my local groce...</td>\n",
              "      <td>1e4iomq</td>\n",
              "      <td>i only paid for half of the price of a cake kn...</td>\n",
              "      <td>more than a year ago i went to my local grocer...</td>\n",
              "      <td>eiomq</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>I lied on my resume because I was desperate fo...</td>\n",
              "      <td>I recently graduated from grad school and have...</td>\n",
              "      <td>1e4fg9e</td>\n",
              "      <td>i lied on my resume because i was desperate fo...</td>\n",
              "      <td>i recently graduated from grad school and have...</td>\n",
              "      <td>efge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>[Extreme Remorse] I relieved my pets from suff...</td>\n",
              "      <td>[Extreme Remorse]\\n\\nI grew up with pets. Yeah...</td>\n",
              "      <td>1e4cg3w</td>\n",
              "      <td>extreme remorse i relieved my pets from suffering</td>\n",
              "      <td>extreme remorse\\n\\ni grew up with pets yeah yo...</td>\n",
              "      <td>ecgw</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a325257-3a23-4f1a-a5c4-0bf1967d319c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a325257-3a23-4f1a-a5c4-0bf1967d319c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a325257-3a23-4f1a-a5c4-0bf1967d319c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d9b33bc9-5364-4576-9b94-9732d9470204\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9b33bc9-5364-4576-9b94-9732d9470204')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d9b33bc9-5364-4576-9b94-9732d9470204 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 824,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 238,\n        \"min\": 0,\n        \"max\": 823,\n        \"num_unique_values\": 824,\n        \"samples\": [\n          610,\n          174,\n          67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 822,\n        \"samples\": [\n          \"Mum caught me masterbaiting and i lied about it omg\",\n          \"I once gaslit my mother into letting me stay up late at night\",\n          \"Popped a tire so he wouldn't drive home drunk and pretended it must of been an accident \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"selftext\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 822,\n        \"samples\": [\n          \"So, I was beating my meat, well, not really bcz you can't beat your meat if you're a girl, anyway, mum caught me masturbating and she said\\n\\u201cOi, what are you doing?\\u201d and I said, \\u201cI'm really itchy, sorry.\\u201d then she gave me smth to put on my, yknow. It was so annoying bcz I had my door open a little bit and I didn't hear her come out of her room\\n\\nAJJSHSHSJSB\",\n          \"Using a throwaway for obvious reasons. Basically today at my job as a security guard I drew something. Usually at work I get bored and start doodling. Well today I got super bored and began drawing an nsfw comic. Yeah I know this was extremely dumb to be doing at work but bear with me. I don't want to be too specific on where I work but basically there are points in the day where I walk around the building. So I go to one of the bathrooms and continue drawing this obscene comic.\\n\\nI'm a few panels in, there isn't any actual sex just a dude with a big pp talking to a girl. Usual nsfw scenario, know what I mean? Then, I put it on the toilet so I can pull my pants up and then I must've forgotten it there. I don't usually do this I usually pick it back up and put it in my pocket. Tbh I'm not entirely sure where I left it. Hopefully it was the bathroom because there are a bunch of cameras in this place. So yeah I left this comic in the bathroom and like 10 minutes later in a place that's off camera I pull out the drawing, but it isn't that drawing it's a different one.\\n\\nSo naturally I begin panicking and I go back to that bathroom but somebody is in the stall so I just pretend to use the bathroom and leave. I check another bathroom where I might've left it about an hour later and it isn't there either. I was only at work for another hour after I left the paper in the bathroom and I didn't hear anything about it.\\n\\nThis means somebody found it. Now depending on who this individual is they might either A. say wtf and throw it away, or B. say wtf and hand it into security or HR. Depending on the decision my job could be at stake. Cause all they have to do is check the cameras and see who went to the bathroom before the person who found it. Hopefully I can lie my way out of this if I'm questioned but if not I get what I deserve and probably won't be able to get a job anywhere else ever again. Moral of the story don't draw bullshit at work, and if you do, keep track of it.\\n\\nWith that said, how fucked am I reddit?\\n\\nTL:DR: I drew something nsfw at work and left it in the bathroom/other location.\\n\\nUpdate: Well, I didn't hear anything about it today at work. I went the whole day paranoid af lmao. But nothing came of it, so whoever found that silly comic threw it away or took it home or just didn't care. Thank you for all the comments everyone! I think my anxiety was just making me assume the worst. \",\n          \"So I'm not proud of this but my drunk brain couldn't think of a better solution on the spot. \\n\\n So I'm at the VFW with my dad and sister, drinking with my dad. He gets pretty drunk and I asked him when he wanted to get going and he said that he'll be good in an hour to drive and that he wants us (sis and me) to follow him. My sister is my DD since she doesn't drink, and she whispers to me that she's worried we won't be good in an hour. So we ask dad to just take a ride with us since my sister lives with my parents and we are just going back to the house. I tell him the car can wait and be picked up tomorrow. He refuses and says he will be fine.\\n\\n He's had a crap ton of shots and a good couple drinks and ALARM BELLS are going off to NOT LET HIM DRIVE. I love my dad, but he is so stubborn so I know the only person who can convince him to NOT drive while buzzed or drunk is my mom. Because of this my mom is the only one who drives him home from the VFW, but she's out of town for the next two weeks. \\n\\nSo I'm like oh shit I need to get other people in on this. I go around asking people we know to get their opinions if he would be okay and they ALL agree he isn't. I tell them I NEED their help to convince my dad to NOT drive. A couple people talk to him and mention \\\"hey you should let your daughter drive\\\" and he laughs it off and says he's fine. It was frustrating. \\n\\nThe only solution we were able to come up with was one person behind him and one person in front of him but my gut is telling me to NOT let him drive.  So I go out to my car (cause I was gonna leave it at the VFW over night) and grab my knife and pop his tire. That was the ONLY solution I could think of. \\n\\nEnd of the night my dad gets in his car, and is about to drive and I go over and I'm like OH NO you have a flat! He is like we can drive to Sheets to get air in it. It took two dudes to convince him to not drive it because the tire was FLAT and he was in denial. He hops into my sister's car bitching about the flat.\\n\\n We all got home safe, but I told my sister I popped his tire and she called me immature and excessive. I believe it was excessive but I didn't know what else to do and I was also drunk. I  just didn't wanna lose my Dad to something I could have prevented. So was I wrong? I just want my dad to be safe, and I wish he would take it more seriously. \\n\\nEdit: I've received a lot of comments saying I should of just let the air out instead of puncturing the tire so I want to clarify a couple things. 1. I also was drunk so I wasn't thinking clearly. 2. Even if I did think to let the air out that means I would of had to have pressed down on the valve which can be time consuming. I would if most likely been caught doing so and I knew we were planning on leaving in about 20 mins. 3. I tried to make the puncture wound tiny as possible to make it look like something else may have gotten to it, but my inebriated brain had poor judgement so it came out to an one inch slash. \\n\\nEdit 2: A lot of people have been asking why didn't I just trick him into giving me his keys, and for those who have experience with drunk people know why and thank you for saying so in the comments. For those who don't know, trying to take keys from a drunk person who thinks they are confident enough to drive is the equivalent of trying to take a ball away from a golden retriever, near impossible. Unfortunately, this isn't the first time this has happened. Seven years ago when he came to visit me when I lived in Florida, we got pretty drunk with my friends. At the end of the night he tried to drive home drunk which surprised me because this was the first time I've ever gotten drunk with my dad and thought he was smarter than that. It took me and seven of my friends to take away his keys which only happened because one of them was brave enough to tackle my dad and grab them. I had to call my mom and put her on the phone with my dad and that was the only way he calmed down enough to take a taxi home. He didn't talk to me for two days because even after he sobered up, he was still convinced he would of been fine. \\n\\nSo, I wasn't about to try that again the other night. Yes, I now realize he needs help. I've been away from home the last four years and came home in 2022. Since I've been home, there wasn't any indication he would be dumb enough to do something like that again, but now I realize my mom has been home majority of that time frame to probably keep him in check.  \\n\\nEdit 3: VFW stands for Veterans of Foreign War and is a club for military vets and their spouses, and family members. My mom is the veteran.\\n\\nUPDATE: So I forgot that the VFW has security cameras and although my intention was to replace the tires I realized I had to replace them before my dad noticed that it was slashed. Things didn't work out as planned since we all woke up around the same time. My sister and I tried to ditch my dad before he had the chance to notice but caught us.\\n\\n So we went to breakfast together then went over to the VFW to grab our cars. He has a portable air compressor so his plan was to just reinflate when we got there but obviously that didn't work. He started kussing up a storm when he noticed that the tire was slashed and my sister decided to take him back home. \\n\\n As fate would had it, he decided he didn't want to mess around with it and decided to nap. Which gave me enough time to go back to the car with a jack and take the tire off, run over to get a new tire and put it back on. My sister helped me throughout the entire process and thank God she did because taking off the old tire was tough! Had to jump on the tire iron to loosen the bolts. Anyways, she drove the car home before my dad could wake up from his nap. \\n\\nHe obviously was confused why I replaced the tire and just told him I wanted to help him out. He thanked me and said he would pay me back, but I don't plan on accepting it. I'm waiting for my mom to return from being out of town so we can all be together when I tell my Dad the truth and hopefully she will back me up. I just hope my Dad doesn't decide to go through the security footage before she gets back. \\n\\nUPDATE 2: So, my Dad ended up going through the security footage and found out it was me. He wasn't mad as I thought he would of been, but I'm not sure how to respond. This is what he ended up texting me. \\n\\n\\\"I'm very shocked after I reviewed the video from Friday at the club. Now I know why you were so converned with replacing my tire. What the hell. If you believe someone shouldn't drive, there would have been many other options. I had a gummy and only had a few drinks and a couple of shots over five hours, normally that would just be me warming up. So I guess me having a great night, you assumed I was drunk. I have a very high tolerance. So I will put this event behind me.\\\"\\n\\nI'm not sure how to respond to this becasue 1. I know it was more than a few and he had two shots and two drinks within the last hour. 2. Him having a gummy and drunk probably won't do him any favors behind the wheel. and 3. I feel like I tried other options that night but he obviously he thought he was fine. \\n\\nI'm tempted just to tell him that I won't pop another tire again as long as he doesn't argue with me when I ask him to have my sister and I take him home instead. However I know he won't take this as seriously. Any ideas how to respond? \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 824,\n        \"samples\": [\n          \"18ddpz7\",\n          \"1ct13ed\",\n          \"1dlmq1m\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 822,\n        \"samples\": [\n          \"mum caught me masterbaiting and i lied about it omg\",\n          \"i once gaslit my mother into letting me stay up late at night\",\n          \"popped a tire so he wouldnt drive home drunk and pretended it must of been an accident \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_selftext\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 821,\n        \"samples\": [\n          \"so i was beating my meat well not really bcz you cant beat your meat if youre a girl anyway mum caught me masturbating and she said\\noi what are you doing and i said im really itchy sorry then she gave me smth to put on my yknow it was so annoying bcz i had my door open a little bit and i didnt hear her come out of her room\\n\\najjshshsjsb\",\n          \"ok this is storys probably a lot more lighthearted than some of the stuff ive seen on this subreddit but im bored and this just popped back into my head so here goes\\n\\nwhen i was like ish i was developing a habit of staying up all night and sleeping during the day during school breaks which as you may imagine my mother wasnt happy about \\n\\nbeing the pre teen little shit i was i argued that no harm was done since i always turned my sleep schedule back around when school started up again and i was still getting sleep just at different times looking back my mother was probably more concerned about me being a shut in who touched less grass than a camel and the eye strain from playing video games and watching youtube in the dark every day but i digress\\n\\nanyway one day i guess she decided to try a more hands one approach to parenting for a change a told me shed be shutting off the internet at pm that night \\n\\nnaturally i was bummed at this but as ive said what i also was was a little shit so i came up with a brilliant scheme to foil my mothers nefarious plan of getting her preteen child to have a healthy life style\\n\\nbasically what i did was i went on youtube and let a video play until the end not relevent but this was the video   yes it was vocaloid shocker i know so the video was fully loaded in\\n\\nthen pm rolled around and mom did as she said and disabled the wifi router leaving me a poor gen z child starved of its one source of entertainment but i didnt care that much actually since i was too busy smirking and metaphorically rubbing my palms together like a cartoon supervillain at my genius scheme\\n\\nlong story short i spent like  hours listening to that one vocaloid song on loop while sketching in my art book until finally i heard my mother wake up from the other room\\n\\nthe look of complete befuddlement on her face when she saw me watching a youtube video like nothing happened was pretty fun ill admit but i was determined to keep a straight face as she asked me how i was doing that\\n\\nputting on my best sheepishly confused expression i shrugged and said something like i dunno you must have pressed the wrong button or something\\n\\nnow obviously this whole plan hinged on my mother not understanding technology to save her life and lo and behold it worked and i guess my mother must have just gave up after that one plan cause she just let me be after that\\n\\nanyway moral of the story dont gaslight your parents kids and maybe go touch some grass\",\n          \"so my girlfriend and i flew to a country with a terrible airline they set out on their mandatory stroll with a little trolley filled with nuts beer and tea someone made a purchase or made a fuss on the other aisle two seats back which caused the flight attendants to look over there for  seconds leaving the trolley unprotected i stole a red label whiskey and concealed it in my jacket im  years old will they get in trouble for it because there is always pandemonium on the flight i doubt they check inventories rather than refill\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 814,\n        \"samples\": [\n          \"cbej\",\n          \"ivyq\",\n          \"cgv\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: select only clean columns and show statistics on  the dataset related to NLP\n",
        "\n",
        "dataset = dataset[['clean_title', 'clean_selftext','id']]\n",
        "dataset.dropna(inplace=True)\n",
        "dataset.info()\n",
        "\n",
        "# Word count statistics\n",
        "dataset['title_word_count'] = dataset['clean_title'].apply(lambda x: len(str(x).split()))\n",
        "dataset['comment_word_count'] = dataset['clean_selftext'].apply(lambda x: len(str(x).split()))\n",
        "print(\"Title Word Count Statistics:\")\n",
        "print(dataset['title_word_count'].describe())\n",
        "print(\"\\nComment Word Count Statistics:\")\n",
        "print(dataset['comment_word_count'].describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pZEbdkmpOvv",
        "outputId": "f75a4637-620c-4069-9b50-113b893df839"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 822 entries, 0 to 823\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   clean_title     822 non-null    object\n",
            " 1   clean_selftext  822 non-null    object\n",
            " 2   id              822 non-null    object\n",
            "dtypes: object(3)\n",
            "memory usage: 25.7+ KB\n",
            "Title Word Count Statistics:\n",
            "count    822.000000\n",
            "mean      13.357664\n",
            "std        3.936284\n",
            "min        1.000000\n",
            "25%       11.000000\n",
            "50%       13.000000\n",
            "75%       15.000000\n",
            "max       53.000000\n",
            "Name: title_word_count, dtype: float64\n",
            "\n",
            "Comment Word Count Statistics:\n",
            "count     822.000000\n",
            "mean      257.379562\n",
            "std       243.037507\n",
            "min         3.000000\n",
            "25%       109.000000\n",
            "50%       194.500000\n",
            "75%       326.750000\n",
            "max      3089.000000\n",
            "Name: comment_word_count, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: performing tokenization, as 'processed_comment'\n",
        "# lemmatization, normalization(stemming and lemmatization), stop-word removal, and word vectorization. after show the modified dataset statistics\n",
        "nltk.download('punkt')\n",
        "# Tokenization\n",
        "dataset['processed_comment'] = dataset['clean_selftext'].apply(nltk.word_tokenize)\n",
        "\n",
        "# Normalization (Stemming and Lemmatization) and Stop-word Removal\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def normalize_text(tokens):\n",
        "    normalized_tokens = [lemmatizer.lemmatize(word.lower()) for word in tokens if word.lower() not in stop_words and word.isalnum()]\n",
        "    return normalized_tokens\n",
        "\n",
        "dataset['processed_comment'] = dataset['processed_comment'].apply(normalize_text)\n",
        "\n",
        "# Word Vectorization (using a simple count vectorizer for demonstration)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform([' '.join(tokens) for tokens in dataset['processed_comment']])\n",
        "\n",
        "# Modified Dataset Statistics\n",
        "print(\"Modified Dataset Statistics:\")\n",
        "print(dataset.head())\n",
        "print(\"\\nShape of word vector matrix:\", X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKsVW-Hzx-a3",
        "outputId": "80dd7836-a82b-4ce8-9096-faca6cef7031"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modified Dataset Statistics:\n",
            "                                         clean_title  \\\n",
            "0  im fed up and i cannot fix it no matter what i do   \n",
            "1  im  years of age and still suck my thumb as a ...   \n",
            "2  i only paid for half of the price of a cake kn...   \n",
            "3  i lied on my resume because i was desperate fo...   \n",
            "4  extreme remorse i relieved my pets from suffering   \n",
            "\n",
            "                                      clean_selftext       id  \\\n",
            "0  when i was younger i was fat but im hilarious ...  1e4xvti   \n",
            "1  im  m and still suck my thumb and honestly don...  1e4xvcj   \n",
            "2  more than a year ago i went to my local grocer...  1e4iomq   \n",
            "3  i recently graduated from grad school and have...  1e4fg9e   \n",
            "4  extreme remorse\\n\\ni grew up with pets yeah yo...  1e4cg3w   \n",
            "\n",
            "   title_word_count  comment_word_count  \\\n",
            "0                13                  99   \n",
            "1                14                  99   \n",
            "2                12                 306   \n",
            "3                11                 192   \n",
            "4                 8                 744   \n",
            "\n",
            "                                   processed_comment  \n",
            "0  [younger, fat, im, hilarious, considered, funn...  \n",
            "1  [im, still, suck, thumb, honestly, dont, want,...  \n",
            "2  [year, ago, went, local, grocery, store, costu...  \n",
            "3  [recently, graduated, grad, school, struggling...  \n",
            "4  [extreme, remorse, grew, pet, yeah, probably, ...  \n",
            "\n",
            "Shape of word vector matrix: (822, 9380)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Apply RNN model to predict the probability of the next word in a sentence.\n",
        "\n",
        "# Prepare data for RNN\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(dataset['processed_comment'])\n",
        "sequences = tokenizer.texts_to_sequences(dataset['processed_comment'])\n",
        "\n",
        "# Padding sequences\n",
        "max_sequence_length = max([len(seq) for seq in sequences])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Create input and output sequences\n",
        "X, y = [], []\n",
        "for seq in padded_sequences:\n",
        "  for i in range(1, len(seq)):\n",
        "    X.append(seq[:i])\n",
        "    y.append(seq[i])\n",
        "\n",
        "X = pad_sequences(X, maxlen=max_sequence_length)\n",
        "y = np.array(y)\n",
        "\n",
        "# Build RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_sequence_length))\n",
        "model.add(SimpleRNN(128))\n",
        "model.add(Dense(len(tokenizer.word_index) + 1, activation='sigmoid'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=30, batch_size=64)\n",
        "\n",
        "# Predict next word probabilities\n",
        "def predict_next_word(text):\n",
        "  sequence = tokenizer.texts_to_sequences([preprocess_text(text)])\n",
        "  padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length)\n",
        "  prediction = model.predict(padded_sequence)[0]\n",
        "  return prediction\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "OUa_o9WvW_mY",
        "outputId": "cee19d59-7cdb-4ecd-9a67-b3a8a34859c0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-23ee269bffb6>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Prepare data for RNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed_comment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed_comment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example from class to test\n",
        "test_data = [\n",
        "    \"I hate programming\",\n",
        "    \"NLP is boring\",\n",
        "    \"Recurrent neural networks are cool\"\n",
        "]\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data)\n",
        "test_padded_sequences = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
        "model.predict(test_padded_sequences)"
      ],
      "metadata": {
        "id": "wwSolMnDakzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fJS5cLlKjHb_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}